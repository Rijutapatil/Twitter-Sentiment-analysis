{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining Assignment 4 - Troll Tweet prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings as _warnings\n",
    "\n",
    "with _warnings.catch_warnings():\n",
    "    _warnings.simplefilter(\"ignore\")\n",
    "    # joblib imports may raise DeprecationWarning on certain Python\n",
    "    # versions\n",
    "    import joblib\n",
    "    from joblib import logger\n",
    "    from joblib import dump, load\n",
    "    from joblib import __version__\n",
    "    from joblib import effective_n_jobs\n",
    "    from joblib import hash\n",
    "    from joblib import cpu_count, Parallel, Memory, delayed\n",
    "    from joblib import parallel_backend, register_parallel_backend\n",
    "\n",
    "\n",
    "    __all__ = [\"parallel_backend\", \"register_parallel_backend\", \"cpu_count\",\n",
    "               \"Parallel\", \"Memory\", \"delayed\", \"effective_n_jobs\", \"hash\",\n",
    "               \"logger\", \"dump\", \"load\", \"joblib\", \"__version__\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the sample dataset of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>account_category</th>\n",
       "      <th>troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No wonder NFL players are kneeling to push the...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>realDonaldTrump Don t worry  the silent majo...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Roni K Patriot Happy to be here</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Merkel si prepara a incontrare  Trump  anche ...</td>\n",
       "      <td>NonEnglish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Salute  ecco la nuova lista delle cure gratui...</td>\n",
       "      <td>NonEnglish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content account_category  troll\n",
       "0  No wonder NFL players are kneeling to push the...       RightTroll      1\n",
       "1    realDonaldTrump Don t worry  the silent majo...       RightTroll      1\n",
       "2                   Roni K Patriot Happy to be here        RightTroll      1\n",
       "3   Merkel si prepara a incontrare  Trump  anche ...       NonEnglish      0\n",
       "4   Salute  ecco la nuova lista delle cure gratui...       NonEnglish      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Assignment_4_data/IRAhandle_tweets_sample_data.csv', sep=',' , encoding='latin-1')\n",
    "\n",
    "# Use latin-1 as encoding since it was throwing 'UnicodeDecodeError, invalid continuation byte'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No wonder NFL players are kneeling to push the false narrative of  evil police   They re all criminals themselves  https   t co iu7lJN3ccm',\n",
       "       '  realDonaldTrump Don t worry  the silent majority who elected you are behind you 100   Keep up the good fight  ',\n",
       "       '  Roni K Patriot Happy to be here ', ...,\n",
       "       'Police are now at a second location near a restaurant investigating a possible bomb    Elizabeth',\n",
       "       'So Trump totally plans on losing this thing I guess if he s already sizing up the field for 2020    https   t co Mn4ZmtLinE',\n",
       "       '  Disciple4Lif  Why I study only the Amplified version of God s Word  per Nehemiah 8 8 instructed even with their vocab larger than English '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things we can observe from the content/tweets columns:\n",
    "\n",
    "We can clearly see that there are some discrepancies in the content file like https, or random characters such as  '@' (for tags) and '#' for hashtags which are commonly used in tweets in the middle so we need to clean it.\n",
    "\n",
    "We can convert the text to lowercase so that it is standardized and easy to work with (It can converted either to upper or lower case)\n",
    "\n",
    "We can also remove Stopwords - this is in accordance with standard nlp practices so that we don't waste time on redundant stop words and give it due importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12014, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content             object\n",
       "account_category    object\n",
       "troll                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first start cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "troll               0\n",
       "account_category    0\n",
       "content             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data seems clean so now we will looking at cleaning 'content' column so its easy to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the tweets column in our dataframe\n",
    "def clean_text(df, content_field):\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\", \"at\")\n",
    "    df[content_field] = df[content_field].str.lower()\n",
    "    return df\n",
    "\n",
    "df = clean_text(df, \"content\")\n",
    "\n",
    "#Additional cleaning with stopwords\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``'] # '...' as seen from the unique \n",
    "\n",
    "def stopwords_removed(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    stopwords_removed = [token for token in tokens if token not in stopwords_list]\n",
    "    return stopwords_removed   \n",
    "\n",
    "df['tokens'] = df['content'].apply(stopwords_removed)\n",
    "df['text'] = df['tokens'].apply(' '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_category</th>\n",
       "      <th>troll</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "      <td>[wonder, nfl, players, kneeling, push, false, ...</td>\n",
       "      <td>wonder nfl players kneeling push false narrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "      <td>[realdonaldtrump, worry, silent, majority, ele...</td>\n",
       "      <td>realdonaldtrump worry silent majority elected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>1</td>\n",
       "      <td>[roni, k, patriot, happy]</td>\n",
       "      <td>roni k patriot happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NonEnglish</td>\n",
       "      <td>0</td>\n",
       "      <td>[merkel, si, prepara, incontrare, trump, anche...</td>\n",
       "      <td>merkel si prepara incontrare trump anche legge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NonEnglish</td>\n",
       "      <td>0</td>\n",
       "      <td>[salute, ecco, la, nuova, lista, delle, cure, ...</td>\n",
       "      <td>salute ecco la nuova lista delle cure gratuite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_category  troll                                             tokens  \\\n",
       "0       RightTroll      1  [wonder, nfl, players, kneeling, push, false, ...   \n",
       "1       RightTroll      1  [realdonaldtrump, worry, silent, majority, ele...   \n",
       "2       RightTroll      1                          [roni, k, patriot, happy]   \n",
       "3       NonEnglish      0  [merkel, si, prepara, incontrare, trump, anche...   \n",
       "4       NonEnglish      0  [salute, ecco, la, nuova, lista, delle, cure, ...   \n",
       "\n",
       "                                                text  \n",
       "0  wonder nfl players kneeling push false narrati...  \n",
       "1  realdonaldtrump worry silent majority elected ...  \n",
       "2                               roni k patriot happy  \n",
       "3  merkel si prepara incontrare trump anche legge...  \n",
       "4  salute ecco la nuova lista delle cure gratuite...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further clean/check\n",
    "df = df.reset_index()\n",
    "df.drop(['content','index'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.troll\n",
    "df=df.drop('troll',axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features=1000)\n",
    "transformed_df = vec.fit_transform(df[\"text\"])\n",
    "X= transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multinomial naïve Bayes classifier on countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.8062583222370173\n",
      "Kappa score: 0.6078526017732144\n",
      "\n",
      "For fold 2\n",
      "Accuracy score: 0.7250332889480693\n",
      "Kappa score: 0.4445355802895852\n",
      "\n",
      "For fold 3\n",
      "Accuracy score: 0.753994673768309\n",
      "Kappa score: 0.5030756199590276\n",
      "\n",
      "For fold 4\n",
      "Accuracy score: 0.8554297135243171\n",
      "Kappa score: 0.702792482511341\n",
      "\n",
      "Average Accuracy score: 0.8554297135243171\n",
      "Average Kappa score: 0.702792482511341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gnb = MultinomialNB()\n",
    "    deci_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print(\"Kappa score:\", cohen_kappa_score(deci_pred, y_test))\n",
    "    print(\"\")\n",
    "    \n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))\n",
    "print(\"Average Kappa score:\", cohen_kappa_score(deci_pred, y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest Classifier on countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.848202396804261\n",
      "Kappa score: 0.5752923806541095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 2\n",
      "Accuracy score: 0.7886151797603196\n",
      "Kappa score: 0.4633864221221956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 3\n",
      "Accuracy score: 0.8278961384820239\n",
      "Kappa score: 0.4998184385002489\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 4\n",
      "Accuracy score: 0.8554297135243171\n",
      "Kappa score: 0.6824313763510327\n",
      "\n",
      "Average Accuracy score: 0.8444370419720186\n",
      "Average Kappa score: 0.6824313763510327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    " \n",
    "\n",
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rfc =  RandomForestClassifier(n_estimators=100, verbose=True, min_samples_split = 5 , criterion = 'entropy' , n_jobs = 20)\n",
    "    deci_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print(\"Kappa score:\", cohen_kappa_score(deci_pred, y_test))\n",
    "    print(\"\")\n",
    "    \n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Average Accuracy score:\", rfc.score(X_test,y_test))\n",
    "print(\"Average Kappa score:\", cohen_kappa_score(deci_pred, y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score obtained from both classifiers is high around 0.84 and is comparable to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=1000,max_df = 10)\n",
    "transformed_df = vec.fit_transform(df[\"text\"])\n",
    "X = transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multinomial naïve Bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 3605 points : 1197\n",
      "Average Accuracy score: 0.6679611650485436\n"
     ]
    }
   ],
   "source": [
    "gnb = MultinomialNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multinomial naïve Bayes classifier with 4-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.6617842876165113\n",
      "Kappa score: 0.27867786220861746\n",
      "\n",
      "For fold 2\n",
      "Accuracy score: 0.631491344873502\n",
      "Kappa score: 0.21296860799757655\n",
      "\n",
      "For fold 3\n",
      "Accuracy score: 0.644474034620506\n",
      "Kappa score: 0.24730997126506893\n",
      "\n",
      "For fold 4\n",
      "Accuracy score: 0.6562291805463024\n",
      "Kappa score: 0.26860175503622685\n",
      "\n",
      "Average Accuracy score: 0.6562291805463024\n",
      "Average Kappa score: 0.26860175503622685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gnb = MultinomialNB()\n",
    "    deci_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print(\"Kappa score:\", cohen_kappa_score(deci_pred, y_test))\n",
    "    print(\"\")\n",
    "    \n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))\n",
    "print(\"Average Kappa score:\", cohen_kappa_score(deci_pred, y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test using Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= transformed_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy score: 0.6638002773925104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classifier\n",
    "\n",
    "rfc =  RandomForestClassifier(n_estimators=100, verbose=True, min_samples_split = 5 , criterion = 'entropy' , n_jobs = 20)\n",
    "#Fitting a Random Forest Classifier\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Average Accuracy score:\", rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test using Random Forest Classifier with 4-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6701065246338216\n",
      "Kappa score: 0.30264888872231177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6291611185086551\n",
      "Kappa score: 0.21889302393325505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6451398135818908\n",
      "Kappa score: 0.2577386305688193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6625582944703531\n",
      "Kappa score: 0.29037820814678983\n",
      "\n",
      "Average Accuracy score: 0.6625582944703531\n",
      "Average Kappa score: 0.29037820814678983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    " \n",
    "\n",
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rfc =  RandomForestClassifier(n_estimators=100, verbose=True, min_samples_split = 5 , criterion = 'entropy' , n_jobs = 20)\n",
    "    deci_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", rfc.score(X_test,y_test))\n",
    "    print(\"Kappa score:\", cohen_kappa_score(deci_pred, y_test))\n",
    "    print(\"\")\n",
    "    \n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Average Accuracy score:\", rfc.score(X_test,y_test))\n",
    "print(\"Average Kappa score:\", cohen_kappa_score(deci_pred, y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is surprising to find that after using TFid vectorizer the accuracy score has reduced considerably for both the classifiers roughly around 0.65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the main dataset of tweets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>harvested_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>...</th>\n",
       "      <th>account_type</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>alt_external_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>article_url</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>tco2_step1</th>\n",
       "      <th>tco3_step1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>We have a sitting Democrat US Senator on tria...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 19:58</td>\n",
       "      <td>10/1/2017 19:59</td>\n",
       "      <td>1052</td>\n",
       "      <td>9636</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.145804e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/914580356430...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Marshawn Lynch arrives to game in anti Trump s...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 22:43</td>\n",
       "      <td>10/1/2017 22:43</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146218e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/damienwoody/status/9145685...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Daughter of fallen Navy Sailor delivers powerf...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 22:50</td>\n",
       "      <td>10/1/2017 22:51</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146235e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/913231923715...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>JUST IN  President Trump dedicates Presidents ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 23:52</td>\n",
       "      <td>10/1/2017 23:52</td>\n",
       "      <td>1062</td>\n",
       "      <td>9642</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146391e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/914639143690...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>19 000 RESPECTING our National Anthem   StandF...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 2:13</td>\n",
       "      <td>10/1/2017 2:13</td>\n",
       "      <td>1050</td>\n",
       "      <td>9645</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.143122e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/914...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201325</td>\n",
       "      <td>1201326</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>HAPPKENDRAHAPPY</td>\n",
       "      <td>Thank you so much and I hope you have a great ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>1311</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>7.793661e+17</td>\n",
       "      <td>http://twitter.com/happkendrahappy/statuses/77...</td>\n",
       "      <td>https://twitter.com/Patriotancestry/status/779...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201326</td>\n",
       "      <td>1201327</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>HAPPKENDRAHAPPY</td>\n",
       "      <td>OutnumberedFNC   ericmtyson I d start watchi...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>1311</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>7.793661e+17</td>\n",
       "      <td>http://twitter.com/happkendrahappy/statuses/77...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201327</td>\n",
       "      <td>1201328</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>HAPPKENDRAHAPPY</td>\n",
       "      <td>7 Ways to Discover  Alien Planets  https   t c...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>9/23/2016 17:05</td>\n",
       "      <td>1311</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>7.793661e+17</td>\n",
       "      <td>http://twitter.com/happkendrahappy/statuses/77...</td>\n",
       "      <td>https://twitter.com/SPACEdotcom/status/7793612...</td>\n",
       "      <td>http://dlvr.it/MKNTzd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201328</td>\n",
       "      <td>1201329</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>HAPPKENDRAHAPPY</td>\n",
       "      <td>Video shows woman shooting at burglars during ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>9/23/2016 17:06</td>\n",
       "      <td>9/23/2016 17:06</td>\n",
       "      <td>1311</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>7.793663e+17</td>\n",
       "      <td>http://twitter.com/happkendrahappy/statuses/77...</td>\n",
       "      <td>http://2wsb.tv/2cp6Kll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201329</td>\n",
       "      <td>1201330</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>HAPPKENDRAHAPPY</td>\n",
       "      <td>Aside from watching this woman defend her life...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>9/23/2016 17:08</td>\n",
       "      <td>9/23/2016 17:09</td>\n",
       "      <td>1311</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>2535818742</td>\n",
       "      <td>7.793668e+17</td>\n",
       "      <td>http://twitter.com/happkendrahappy/statuses/77...</td>\n",
       "      <td>http://www.wsbtv.com/news/local/gwinnett-count...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201330 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 external_author_id           author  \\\n",
       "0                 1           9.06e+17           10_GOP   \n",
       "1                 2           9.06e+17           10_GOP   \n",
       "2                 3           9.06e+17           10_GOP   \n",
       "3                 4           9.06e+17           10_GOP   \n",
       "4                 5           9.06e+17           10_GOP   \n",
       "...             ...                ...              ...   \n",
       "1201325     1201326         2535818742  HAPPKENDRAHAPPY   \n",
       "1201326     1201327         2535818742  HAPPKENDRAHAPPY   \n",
       "1201327     1201328         2535818742  HAPPKENDRAHAPPY   \n",
       "1201328     1201329         2535818742  HAPPKENDRAHAPPY   \n",
       "1201329     1201330         2535818742  HAPPKENDRAHAPPY   \n",
       "\n",
       "                                                   content         region  \\\n",
       "0         We have a sitting Democrat US Senator on tria...        Unknown   \n",
       "1        Marshawn Lynch arrives to game in anti Trump s...        Unknown   \n",
       "2        Daughter of fallen Navy Sailor delivers powerf...        Unknown   \n",
       "3        JUST IN  President Trump dedicates Presidents ...        Unknown   \n",
       "4        19 000 RESPECTING our National Anthem   StandF...        Unknown   \n",
       "...                                                    ...            ...   \n",
       "1201325  Thank you so much and I hope you have a great ...  United States   \n",
       "1201326    OutnumberedFNC   ericmtyson I d start watchi...  United States   \n",
       "1201327  7 Ways to Discover  Alien Planets  https   t c...  United States   \n",
       "1201328  Video shows woman shooting at burglars during ...  United States   \n",
       "1201329  Aside from watching this woman defend her life...  United States   \n",
       "\n",
       "        language     publish_date   harvested_date  following  followers  ...  \\\n",
       "0        English  10/1/2017 19:58  10/1/2017 19:59       1052       9636  ...   \n",
       "1        English  10/1/2017 22:43  10/1/2017 22:43       1054       9637  ...   \n",
       "2        English  10/1/2017 22:50  10/1/2017 22:51       1054       9637  ...   \n",
       "3        English  10/1/2017 23:52  10/1/2017 23:52       1062       9642  ...   \n",
       "4        English   10/1/2017 2:13   10/1/2017 2:13       1050       9645  ...   \n",
       "...          ...              ...              ...        ...        ...  ...   \n",
       "1201325  English  9/23/2016 17:05  9/23/2016 17:05       1311       1688  ...   \n",
       "1201326  English  9/23/2016 17:05  9/23/2016 17:05       1311       1688  ...   \n",
       "1201327  English  9/23/2016 17:05  9/23/2016 17:05       1311       1688  ...   \n",
       "1201328  English  9/23/2016 17:06  9/23/2016 17:06       1311       1688  ...   \n",
       "1201329  English  9/23/2016 17:08  9/23/2016 17:09       1311       1688  ...   \n",
       "\n",
       "         account_type retweet account_category  new_june_2018  \\\n",
       "0               Right       0       RightTroll              0   \n",
       "1               Right       0       RightTroll              0   \n",
       "2               Right       1       RightTroll              0   \n",
       "3               Right       0       RightTroll              0   \n",
       "4               Right       1       RightTroll              0   \n",
       "...               ...     ...              ...            ...   \n",
       "1201325         Right       1       RightTroll              0   \n",
       "1201326         Right       1       RightTroll              0   \n",
       "1201327         Right       1       RightTroll              0   \n",
       "1201328         Right       1       RightTroll              0   \n",
       "1201329         Right       1       RightTroll              0   \n",
       "\n",
       "            alt_external_id      tweet_id  \\\n",
       "0        905874659358453760  9.145804e+17   \n",
       "1        905874659358453760  9.146218e+17   \n",
       "2        905874659358453760  9.146235e+17   \n",
       "3        905874659358453760  9.146391e+17   \n",
       "4        905874659358453760  9.143122e+17   \n",
       "...                     ...           ...   \n",
       "1201325          2535818742  7.793661e+17   \n",
       "1201326          2535818742  7.793661e+17   \n",
       "1201327          2535818742  7.793661e+17   \n",
       "1201328          2535818742  7.793663e+17   \n",
       "1201329          2535818742  7.793668e+17   \n",
       "\n",
       "                                               article_url  \\\n",
       "0        http://twitter.com/905874659358453760/statuses...   \n",
       "1        http://twitter.com/905874659358453760/statuses...   \n",
       "2        http://twitter.com/905874659358453760/statuses...   \n",
       "3        http://twitter.com/905874659358453760/statuses...   \n",
       "4        http://twitter.com/905874659358453760/statuses...   \n",
       "...                                                    ...   \n",
       "1201325  http://twitter.com/happkendrahappy/statuses/77...   \n",
       "1201326  http://twitter.com/happkendrahappy/statuses/77...   \n",
       "1201327  http://twitter.com/happkendrahappy/statuses/77...   \n",
       "1201328  http://twitter.com/happkendrahappy/statuses/77...   \n",
       "1201329  http://twitter.com/happkendrahappy/statuses/77...   \n",
       "\n",
       "                                                tco1_step1  \\\n",
       "0        https://twitter.com/10_gop/status/914580356430...   \n",
       "1        https://twitter.com/damienwoody/status/9145685...   \n",
       "2        https://twitter.com/10_gop/status/913231923715...   \n",
       "3        https://twitter.com/10_gop/status/914639143690...   \n",
       "4        https://twitter.com/realDonaldTrump/status/914...   \n",
       "...                                                    ...   \n",
       "1201325  https://twitter.com/Patriotancestry/status/779...   \n",
       "1201326                                                NaN   \n",
       "1201327  https://twitter.com/SPACEdotcom/status/7793612...   \n",
       "1201328                             http://2wsb.tv/2cp6Kll   \n",
       "1201329  http://www.wsbtv.com/news/local/gwinnett-count...   \n",
       "\n",
       "                    tco2_step1 tco3_step1  \n",
       "0                          NaN        NaN  \n",
       "1                          NaN        NaN  \n",
       "2                          NaN        NaN  \n",
       "3                          NaN        NaN  \n",
       "4                          NaN        NaN  \n",
       "...                        ...        ...  \n",
       "1201325                    NaN        NaN  \n",
       "1201326                    NaN        NaN  \n",
       "1201327  http://dlvr.it/MKNTzd        NaN  \n",
       "1201328                    NaN        NaN  \n",
       "1201329                    NaN        NaN  \n",
       "\n",
       "[1201330 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df = pd.read_csv('Assignment_4_data/IRAhandle_master_data.csv', sep=',' , encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Use latin-1 as encoding since it was throwing 'UnicodeDecodeError, invalid continuation byte'\n",
    "m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RightTroll      367871\n",
       "NonEnglish      238452\n",
       "LeftTroll       177323\n",
       "NewsFeed        157809\n",
       "HashtagGamer    132389\n",
       "Commercial      120699\n",
       "Fearmonger        4794\n",
       "Unknown           1993\n",
       "Name: account_category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.account_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the troll column in the master dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>harvested_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>alt_external_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>article_url</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>tco2_step1</th>\n",
       "      <th>tco3_step1</th>\n",
       "      <th>troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>We have a sitting Democrat US Senator on tria...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 19:58</td>\n",
       "      <td>10/1/2017 19:59</td>\n",
       "      <td>1052</td>\n",
       "      <td>9636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.145804e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/914580356430...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Marshawn Lynch arrives to game in anti Trump s...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 22:43</td>\n",
       "      <td>10/1/2017 22:43</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146218e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/damienwoody/status/9145685...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Daughter of fallen Navy Sailor delivers powerf...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 22:50</td>\n",
       "      <td>10/1/2017 22:51</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146235e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/913231923715...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>JUST IN  President Trump dedicates Presidents ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 23:52</td>\n",
       "      <td>10/1/2017 23:52</td>\n",
       "      <td>1062</td>\n",
       "      <td>9642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.146391e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/10_gop/status/914639143690...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9.06e+17</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>19 000 RESPECTING our National Anthem   StandF...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>10/1/2017 2:13</td>\n",
       "      <td>10/1/2017 2:13</td>\n",
       "      <td>1050</td>\n",
       "      <td>9645</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "      <td>9.143122e+17</td>\n",
       "      <td>http://twitter.com/905874659358453760/statuses...</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/914...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 external_author_id  author  \\\n",
       "0           1           9.06e+17  10_GOP   \n",
       "1           2           9.06e+17  10_GOP   \n",
       "2           3           9.06e+17  10_GOP   \n",
       "3           4           9.06e+17  10_GOP   \n",
       "4           5           9.06e+17  10_GOP   \n",
       "\n",
       "                                             content   region language  \\\n",
       "0   We have a sitting Democrat US Senator on tria...  Unknown  English   \n",
       "1  Marshawn Lynch arrives to game in anti Trump s...  Unknown  English   \n",
       "2  Daughter of fallen Navy Sailor delivers powerf...  Unknown  English   \n",
       "3  JUST IN  President Trump dedicates Presidents ...  Unknown  English   \n",
       "4  19 000 RESPECTING our National Anthem   StandF...  Unknown  English   \n",
       "\n",
       "      publish_date   harvested_date  following  followers  ...  retweet  \\\n",
       "0  10/1/2017 19:58  10/1/2017 19:59       1052       9636  ...        0   \n",
       "1  10/1/2017 22:43  10/1/2017 22:43       1054       9637  ...        0   \n",
       "2  10/1/2017 22:50  10/1/2017 22:51       1054       9637  ...        1   \n",
       "3  10/1/2017 23:52  10/1/2017 23:52       1062       9642  ...        0   \n",
       "4   10/1/2017 2:13   10/1/2017 2:13       1050       9645  ...        1   \n",
       "\n",
       "  account_category new_june_2018     alt_external_id      tweet_id  \\\n",
       "0       RightTroll             0  905874659358453760  9.145804e+17   \n",
       "1       RightTroll             0  905874659358453760  9.146218e+17   \n",
       "2       RightTroll             0  905874659358453760  9.146235e+17   \n",
       "3       RightTroll             0  905874659358453760  9.146391e+17   \n",
       "4       RightTroll             0  905874659358453760  9.143122e+17   \n",
       "\n",
       "                                         article_url  \\\n",
       "0  http://twitter.com/905874659358453760/statuses...   \n",
       "1  http://twitter.com/905874659358453760/statuses...   \n",
       "2  http://twitter.com/905874659358453760/statuses...   \n",
       "3  http://twitter.com/905874659358453760/statuses...   \n",
       "4  http://twitter.com/905874659358453760/statuses...   \n",
       "\n",
       "                                          tco1_step1  tco2_step1 tco3_step1  \\\n",
       "0  https://twitter.com/10_gop/status/914580356430...         NaN        NaN   \n",
       "1  https://twitter.com/damienwoody/status/9145685...         NaN        NaN   \n",
       "2  https://twitter.com/10_gop/status/913231923715...         NaN        NaN   \n",
       "3  https://twitter.com/10_gop/status/914639143690...         NaN        NaN   \n",
       "4  https://twitter.com/realDonaldTrump/status/914...         NaN        NaN   \n",
       "\n",
       "  troll  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df['troll'] = np.where((m_df['account_category'] == 'RightTroll') | (m_df['account_category'] == 'LeftTroll'), 1, 0)\n",
    "m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    656136\n",
       "1    545194\n",
       "Name: troll, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if troll column has unique values\n",
    "m_df.troll.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the value_counts above we can see that there are lot of values for account categories so let's club these values HashtagGamer, Commercial, Fearmonger, Unknown and NonEnglish into 'Other' since they haven't been prominant in the exploratory phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201330, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Other         0.414813\n",
       "RightTroll    0.306220\n",
       "LeftTroll     0.147606\n",
       "NewsFeed      0.131362\n",
       "Name: account_category, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming account_categories\n",
    "m_df['account_category'].replace({'HashtagGamer': 'Other','NonEnglish': 'Other', 'Unknown': 'Other', \n",
    "                            'Fearmonger': 'Other', 'Commercial': 'Other'}, inplace = True)\n",
    "print(m_df.shape)\n",
    "m_df.account_category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>harvested_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>alt_external_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>article_url</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>tco2_step1</th>\n",
       "      <th>tco3_step1</th>\n",
       "      <th>troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1199500</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>1201330</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>1201330</td>\n",
       "      <td>903381</td>\n",
       "      <td>289681</td>\n",
       "      <td>8168</td>\n",
       "      <td>1.201330e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>911</td>\n",
       "      <td>1061</td>\n",
       "      <td>1044711</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>462046</td>\n",
       "      <td>471589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1201330</td>\n",
       "      <td>717152</td>\n",
       "      <td>205488</td>\n",
       "      <td>7172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.92e+17</td>\n",
       "      <td>EXQUOTE</td>\n",
       "      <td>Ð  Ð Ð Ñ Ð Ð Ðµ Ð Ð Ñ Ð   ÐÐ Ð Ð Ð Ð Ð Ð Ð  â...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>8/15/2017 17:01</td>\n",
       "      <td>12/29/2016 4:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3272640600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/891941754282188801/statuses...</td>\n",
       "      <td>https://twibble.io</td>\n",
       "      <td>https://twibble.io</td>\n",
       "      <td>http://dlvr.it/PQdNjm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64365</td>\n",
       "      <td>59174</td>\n",
       "      <td>201</td>\n",
       "      <td>845288</td>\n",
       "      <td>952915</td>\n",
       "      <td>121</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>498327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1747</td>\n",
       "      <td>5167</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>6.006655e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.569479e+03</td>\n",
       "      <td>4.273418e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.553337e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.542099e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.687101e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.538253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.467942e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.740071e+03</td>\n",
       "      <td>7.572600e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.980011e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.354163e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.045932e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.978635e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.666183e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.003332e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.250000e+02</td>\n",
       "      <td>2.510000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.690479e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>6.006655e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.273000e+03</td>\n",
       "      <td>8.880000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.850686e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.009978e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.148000e+03</td>\n",
       "      <td>2.721000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.570004e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.201330e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.154700e+04</td>\n",
       "      <td>5.910000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000722e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0 external_author_id   author  \\\n",
       "count   1.201330e+06            1201330  1201330   \n",
       "unique           NaN                911     1061   \n",
       "top              NaN           8.92e+17  EXQUOTE   \n",
       "freq             NaN              64365    59174   \n",
       "mean    6.006655e+05                NaN      NaN   \n",
       "std     3.467942e+05                NaN      NaN   \n",
       "min     1.000000e+00                NaN      NaN   \n",
       "25%     3.003332e+05                NaN      NaN   \n",
       "50%     6.006655e+05                NaN      NaN   \n",
       "75%     9.009978e+05                NaN      NaN   \n",
       "max     1.201330e+06                NaN      NaN   \n",
       "\n",
       "                                                  content         region  \\\n",
       "count                                             1201330        1199500   \n",
       "unique                                            1044711             25   \n",
       "top     Ð  Ð Ð Ñ Ð Ð Ðµ Ð Ð Ñ Ð   ÐÐ Ð Ð Ð Ð Ð Ð Ð  â...  United States   \n",
       "freq                                                  201         845288   \n",
       "mean                                                  NaN            NaN   \n",
       "std                                                   NaN            NaN   \n",
       "min                                                   NaN            NaN   \n",
       "25%                                                   NaN            NaN   \n",
       "50%                                                   NaN            NaN   \n",
       "75%                                                   NaN            NaN   \n",
       "max                                                   NaN            NaN   \n",
       "\n",
       "       language     publish_date   harvested_date     following     followers  \\\n",
       "count   1201330          1201330          1201330  1.201330e+06  1.201330e+06   \n",
       "unique       56           462046           471589           NaN           NaN   \n",
       "top     English  8/15/2017 17:01  12/29/2016 4:01           NaN           NaN   \n",
       "freq     952915              121              299           NaN           NaN   \n",
       "mean        NaN              NaN              NaN  2.569479e+03  4.273418e+03   \n",
       "std         NaN              NaN              NaN  3.740071e+03  7.572600e+03   \n",
       "min         NaN              NaN              NaN -1.000000e+00 -1.000000e+00   \n",
       "25%         NaN              NaN              NaN  2.250000e+02  2.510000e+02   \n",
       "50%         NaN              NaN              NaN  1.273000e+03  8.880000e+02   \n",
       "75%         NaN              NaN              NaN  3.148000e+03  2.721000e+03   \n",
       "max         NaN              NaN              NaN  3.154700e+04  5.910000e+04   \n",
       "\n",
       "        ...       retweet account_category new_june_2018  alt_external_id  \\\n",
       "count   ...  1.201330e+06          1201330  1.201330e+06          1201330   \n",
       "unique  ...           NaN                4           NaN             1065   \n",
       "top     ...           NaN            Other           NaN       3272640600   \n",
       "freq    ...           NaN           498327           NaN            45886   \n",
       "mean    ...  4.553337e-01              NaN  2.542099e-01              NaN   \n",
       "std     ...  4.980011e-01              NaN  4.354163e-01              NaN   \n",
       "min     ...  0.000000e+00              NaN  0.000000e+00              NaN   \n",
       "25%     ...  0.000000e+00              NaN  0.000000e+00              NaN   \n",
       "50%     ...  0.000000e+00              NaN  0.000000e+00              NaN   \n",
       "75%     ...  1.000000e+00              NaN  1.000000e+00              NaN   \n",
       "max     ...  1.000000e+00              NaN  1.000000e+00              NaN   \n",
       "\n",
       "            tweet_id                                        article_url  \\\n",
       "count   1.201330e+06                                            1201330   \n",
       "unique           NaN                                            1201330   \n",
       "top              NaN  http://twitter.com/891941754282188801/statuses...   \n",
       "freq             NaN                                                  1   \n",
       "mean    7.687101e+17                                                NaN   \n",
       "std     1.045932e+17                                                NaN   \n",
       "min     1.666183e+17                                                NaN   \n",
       "25%     6.690479e+17                                                NaN   \n",
       "50%     7.850686e+17                                                NaN   \n",
       "75%     8.570004e+17                                                NaN   \n",
       "max     1.000722e+18                                                NaN   \n",
       "\n",
       "                tco1_step1          tco2_step1             tco3_step1  \\\n",
       "count               903381              289681                   8168   \n",
       "unique              717152              205488                   7172   \n",
       "top     https://twibble.io  https://twibble.io  http://dlvr.it/PQdNjm   \n",
       "freq                  1747                5167                     65   \n",
       "mean                   NaN                 NaN                    NaN   \n",
       "std                    NaN                 NaN                    NaN   \n",
       "min                    NaN                 NaN                    NaN   \n",
       "25%                    NaN                 NaN                    NaN   \n",
       "50%                    NaN                 NaN                    NaN   \n",
       "75%                    NaN                 NaN                    NaN   \n",
       "max                    NaN                 NaN                    NaN   \n",
       "\n",
       "               troll  \n",
       "count   1.201330e+06  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean    4.538253e-01  \n",
       "std     4.978635e-01  \n",
       "min     0.000000e+00  \n",
       "25%     0.000000e+00  \n",
       "50%     0.000000e+00  \n",
       "75%     1.000000e+00  \n",
       "max     1.000000e+00  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove the \"harvested_date\" since I don't need it for my analysis and keep 'publish_date' since one datetime column is enough.\n",
    "We can also see the addition of 'Unnamed: 0' is done when file is imported ; it is just a replication of the index so I can remove that.\n",
    "\n",
    "Using the describe function, we can also see which columns are unique or not ; or how many unique values compared to total dataset. \n",
    "\n",
    "There are roughly 15% tweets which are duplicates since there are only 1044711 unique tweets from 'content' column. However, these 'unique' tweets could be retweets which contain the same information or text. We can use this column to see the weight given to each word as done above on the sample dataset.\n",
    "\n",
    "It also looks like there are some NaN values for \"external_author_id\", which is the author account ID from Twitter. Since we already have the Twitter Handle as the \"author\" column for each tweet we won't be using the \"external_author_id\" in this analysis and will remove this field from the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns that won't be used\n",
    "m_df = m_df.drop(['harvested_date', 'Unnamed: 0', 'external_author_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author               object\n",
       "content              object\n",
       "region               object\n",
       "language             object\n",
       "publish_date         object\n",
       "following             int64\n",
       "followers             int64\n",
       "updates               int64\n",
       "post_type            object\n",
       "account_type         object\n",
       "retweet               int64\n",
       "account_category     object\n",
       "new_june_2018         int64\n",
       "alt_external_id      object\n",
       "tweet_id            float64\n",
       "article_url          object\n",
       "tco1_step1           object\n",
       "tco2_step1           object\n",
       "tco3_step1           object\n",
       "troll                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English      0.793217\n",
       "Russian      0.124268\n",
       "German       0.042542\n",
       "Italian      0.011054\n",
       "Ukrainian    0.008257\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's look at the languages of the tweets:\n",
    "\n",
    "m_df.language.value_counts(normalize=True).head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of all tweets are in english. For ease of research I'll only keep the tweets that are english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(952915, 20)\n"
     ]
    }
   ],
   "source": [
    "#Update data to only contain 'English' tweets\n",
    "m_df = m_df.loc[m_df.language == 'English']\n",
    "print(m_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df.drop(['language'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tco3_step1          945022\n",
       "tco2_step1          744342\n",
       "post_type           557435\n",
       "tco1_step1          271244\n",
       "region                 511\n",
       "troll                    0\n",
       "content                  0\n",
       "publish_date             0\n",
       "following                0\n",
       "followers                0\n",
       "updates                  0\n",
       "retweet                  0\n",
       "account_type             0\n",
       "account_category         0\n",
       "new_june_2018            0\n",
       "alt_external_id          0\n",
       "tweet_id                 0\n",
       "article_url              0\n",
       "author                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see if there is any missing data in the dataset\n",
    "m_df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States           0.829662\n",
       "Unknown                 0.166414\n",
       "Azerbaijan              0.001414\n",
       "United Kingdom          0.000835\n",
       "Germany                 0.000445\n",
       "Italy                   0.000348\n",
       "Russian Federation      0.000246\n",
       "Iraq                    0.000173\n",
       "Afghanistan             0.000157\n",
       "Belarus                 0.000106\n",
       "Israel                  0.000073\n",
       "United Arab Emirates    0.000058\n",
       "Ukraine                 0.000028\n",
       "Egypt                   0.000022\n",
       "France                  0.000012\n",
       "Malaysia                0.000004\n",
       "Serbia                  0.000002\n",
       "Hong Kong               0.000001\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 511 missing values are there for region so let's look at that in detail\n",
    "\n",
    "#value count of region\n",
    "m_df.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "83% of region values are \"United States\" and 17% of region values are \"Unknown\". Since all the missing values here do speak English, I'll replace the Nan with Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'United States', 'Italy', 'United Arab Emirates',\n",
       "       'Israel', 'Azerbaijan', 'United Kingdom', 'Russian Federation',\n",
       "       'Iraq', 'Germany', 'France', 'Ukraine', 'Serbia', 'Egypt',\n",
       "       'Hong Kong', 'Belarus', 'Malaysia', 'Afghanistan'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename region nan values to 'unknown' because it already has 'unknown' as a value. So it is better to label them \\\n",
    "# as unknown than to remove the nan values.\n",
    "\n",
    "m_df['region'].fillna(value='Unknown', inplace = True)\n",
    "m_df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETWEET        0.938922\n",
       "QUOTE_TWEET    0.061078\n",
       "Name: post_type, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.post_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'RETWEET', 'QUOTE_TWEET'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.post_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT_RETWEET', 'RETWEET', 'QUOTE_TWEET'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there is no relation between the retweet value and nan values so we can update the field using \n",
    "\n",
    "m_df['post_type'].fillna(value='NOT_RETWEET', inplace = True)\n",
    "m_df.post_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the nans are not retweets. Therefore, since this isn't actually missing data we can replace the NaN values under post_type with NOT_RETWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tco3_step1          945022\n",
       "tco2_step1          744342\n",
       "tco1_step1          271244\n",
       "troll                    0\n",
       "post_type                0\n",
       "content                  0\n",
       "region                   0\n",
       "publish_date             0\n",
       "following                0\n",
       "followers                0\n",
       "updates                  0\n",
       "retweet                  0\n",
       "account_type             0\n",
       "account_category         0\n",
       "new_june_2018            0\n",
       "alt_external_id          0\n",
       "tweet_id                 0\n",
       "article_url              0\n",
       "author                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm there is no more missing data\n",
    "m_df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'tco1_step1' , 'tco_step1', 'tco3_step1' are nothing but URLs so we can remove them also from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature selection using chi squared -- regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will sample the data randomly as the file is too large and was causing my system to crash\n",
    "# This code will run even if the values are not sample but for simplicity I will sample it.\n",
    "\n",
    "m_df = m_df.sample(n= 30000)\n",
    "m_df.troll.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1/2016 0:30 9/9/2017 3:07\n"
     ]
    }
   ],
   "source": [
    "start_date_tweet = m_df['publish_date'].min()\n",
    "end_date_tweet = m_df['publish_date'].max()\n",
    "\n",
    "print(start_date_tweet, end_date_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have almost 4 years of tweets starting 1st January 2013 until the 9th of September 2017. Time also appears with these dates, so let's create a new column to hold only the date component of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make date as datetime publish_date by creating a string column\n",
    "m_df['publish_date'] = pd.to_datetime(m_df['publish_date'])\n",
    "\n",
    "m_df['publish_date'] = pd.to_datetime(m_df['publish_date'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the tweets column in our dataframe\n",
    "def clean_text(df, content_field):\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\", \"at\")\n",
    "    df[content_field] = df[content_field].str.lower()\n",
    "    return df\n",
    "\n",
    "m_df2 = clean_text(m_df, \"content\")\n",
    "\n",
    "#Additional cleaning with stopwords\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``'] # '...' as seen from the unique \n",
    "\n",
    "def stopwords_removed(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    stopwords_removed = [token for token in tokens if token not in stopwords_list]\n",
    "    return stopwords_removed   \n",
    "\n",
    "m_df2['tokens'] = m_df2['content'].apply(stopwords_removed)\n",
    "m_df2['text'] = m_df2['tokens'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>region</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>account_type</th>\n",
       "      <th>retweet</th>\n",
       "      <th>...</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>alt_external_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>article_url</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>tco2_step1</th>\n",
       "      <th>tco3_step1</th>\n",
       "      <th>troll</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>757329</td>\n",
       "      <td>DAILYSANFRAN</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6099</td>\n",
       "      <td>17514</td>\n",
       "      <td>42080</td>\n",
       "      <td>NOT_RETWEET</td>\n",
       "      <td>local</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2495567768</td>\n",
       "      <td>8.704203e+17</td>\n",
       "      <td>http://twitter.com/2495567768/statuses/8704203...</td>\n",
       "      <td>https://twitter.com/DailySanFran/status/870420...</td>\n",
       "      <td>http://kron4.com/2017/06/01/minor-arrested-in-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[minor, arrested, string, bart, auto, burglari...</td>\n",
       "      <td>minor arrested string bart auto burglaries co ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>874869</td>\n",
       "      <td>DICKYIRWIN</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>3265</td>\n",
       "      <td>3440</td>\n",
       "      <td>4232</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Hashtager</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2598367019</td>\n",
       "      <td>8.057893e+17</td>\n",
       "      <td>http://twitter.com/2598367019/statuses/8057892...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[time, sucking, assholes, tsa, alternativeacro...</td>\n",
       "      <td>time sucking assholes tsa alternativeacronymin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>842418</td>\n",
       "      <td>DEBORRTH</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>1983</td>\n",
       "      <td>470</td>\n",
       "      <td>264</td>\n",
       "      <td>NOT_RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>890488664215756800</td>\n",
       "      <td>8.920326e+17</td>\n",
       "      <td>http://twitter.com/890488664215756801/statuses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[lost, azredhen, nice, air, drywall, guy, love]</td>\n",
       "      <td>lost azredhen nice air drywall guy love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>296400</td>\n",
       "      <td>BEN_SAR_GENT</td>\n",
       "      <td>United States</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>182</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2580772991</td>\n",
       "      <td>6.437198e+17</td>\n",
       "      <td>http://twitter.com/Ben_Sar_Gent/statuses/64371...</td>\n",
       "      <td>https://twitter.com/Libertea2012/status/643383...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[hillaryclinton, hardly, put, jail, though, e,...</td>\n",
       "      <td>hillaryclinton hardly put jail though e mail s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>203247</td>\n",
       "      <td>ARCHIEOLIVERS</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>3357</td>\n",
       "      <td>2622</td>\n",
       "      <td>2027</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1686370159</td>\n",
       "      <td>8.125507e+17</td>\n",
       "      <td>http://twitter.com/1686370159/statuses/8125506...</td>\n",
       "      <td>http://ift.tt/2i1QXxl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[news, post, ex, campaign, aides, building, pr...</td>\n",
       "      <td>news post ex campaign aides building pro trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         author         region publish_date  following  followers  \\\n",
       "0  757329   DAILYSANFRAN  United States   2017-06-01       6099      17514   \n",
       "1  874869     DICKYIRWIN  United States   2016-12-05       3265       3440   \n",
       "2  842418       DEBORRTH        Unknown   2017-07-31       1983        470   \n",
       "3  296400   BEN_SAR_GENT  United States   2015-09-15        128         11   \n",
       "4  203247  ARCHIEOLIVERS  United States   2016-12-24       3357       2622   \n",
       "\n",
       "   updates    post_type account_type  retweet  ... new_june_2018  \\\n",
       "0    42080  NOT_RETWEET        local        0  ...             0   \n",
       "1     4232      RETWEET    Hashtager        1  ...             0   \n",
       "2      264  NOT_RETWEET        Right        0  ...             0   \n",
       "3      182      RETWEET        Right        1  ...             0   \n",
       "4     2027      RETWEET        Right        1  ...             0   \n",
       "\n",
       "      alt_external_id      tweet_id  \\\n",
       "0          2495567768  8.704203e+17   \n",
       "1          2598367019  8.057893e+17   \n",
       "2  890488664215756800  8.920326e+17   \n",
       "3          2580772991  6.437198e+17   \n",
       "4          1686370159  8.125507e+17   \n",
       "\n",
       "                                         article_url  \\\n",
       "0  http://twitter.com/2495567768/statuses/8704203...   \n",
       "1  http://twitter.com/2598367019/statuses/8057892...   \n",
       "2  http://twitter.com/890488664215756801/statuses...   \n",
       "3  http://twitter.com/Ben_Sar_Gent/statuses/64371...   \n",
       "4  http://twitter.com/1686370159/statuses/8125506...   \n",
       "\n",
       "                                          tco1_step1  \\\n",
       "0  https://twitter.com/DailySanFran/status/870420...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://twitter.com/Libertea2012/status/643383...   \n",
       "4                              http://ift.tt/2i1QXxl   \n",
       "\n",
       "                                          tco2_step1 tco3_step1 troll  \\\n",
       "0  http://kron4.com/2017/06/01/minor-arrested-in-...        NaN     0   \n",
       "1                                                NaN        NaN     0   \n",
       "2                                                NaN        NaN     1   \n",
       "3                                                NaN        NaN     1   \n",
       "4                                                NaN        NaN     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [minor, arrested, string, bart, auto, burglari...   \n",
       "1  [time, sucking, assholes, tsa, alternativeacro...   \n",
       "2    [lost, azredhen, nice, air, drywall, guy, love]   \n",
       "3  [hillaryclinton, hardly, put, jail, though, e,...   \n",
       "4  [news, post, ex, campaign, aides, building, pr...   \n",
       "\n",
       "                                                text  \n",
       "0  minor arrested string bart auto burglaries co ...  \n",
       "1  time sucking assholes tsa alternativeacronymin...  \n",
       "2            lost azredhen nice air drywall guy love  \n",
       "3  hillaryclinton hardly put jail though e mail s...  \n",
       "4  news post ex campaign aides building pro trump...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further clean/check\n",
    "m_df2 = m_df2.reset_index()\n",
    "m_df2.drop(['content'], axis=1, inplace=True)\n",
    "m_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(max_features=4000)\n",
    "transformed_df = vec.fit_transform(m_df2[\"text\"])\n",
    "transformed_df.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = m_df2[['troll']].to_numpy()\n",
    "y = np.squeeze(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a multinomial naïve Bayes classifier on Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843231957285526\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "gnb = MultinomialNB(alpha=.01)\n",
    "gnb.fit(transformed_df, y)\n",
    "vectors_test = vec.transform(m_df2[\"text\"])\n",
    "y_pred = gnb.predict(vectors_test)\n",
    "# y_pred = gnb.predict(m_df2[\"text\"])\n",
    "# print(\"Average Accuracy score:\", gnb.score(vectors_test,y))\n",
    "f1_score = metrics.f1_score(y, y_pred, average='macro')\n",
    "acc_score = metrics.accuracy_score(y, y_pred)\n",
    "print(f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.819890681242501\n",
      "\n",
      "\n",
      "For fold 2\n",
      "Accuracy score: 0.8165333333333333\n",
      "\n",
      "\n",
      "For fold 3\n",
      "Accuracy score: 0.8174666666666667\n",
      "\n",
      "\n",
      "For fold 4\n",
      "Accuracy score: 0.820776103480464\n",
      "\n",
      "\n",
      "Average Accuracy score: 0.820776103480464\n",
      "Classification report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      3252\n",
      "           1       0.84      0.84      0.84      4247\n",
      "\n",
      "    accuracy                           0.82      7499\n",
      "   macro avg       0.82      0.82      0.82      7499\n",
      "weighted avg       0.82      0.82      0.82      7499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df.toarray()\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gnb = MultinomialNB()\n",
    "#     print(type(X))\n",
    "#     print(np.any(np.isnan(X_train)))\n",
    "    gnb.fit(X_train, y_train)\n",
    "    deci_pred = gnb.predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print()\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))\n",
    "print (\"Classification report = \\n\",classification_report(y_test, deci_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a Random Forest classifier on Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patil/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.8118917477669644\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patil/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 2\n",
      "Accuracy score: 0.8126666666666666\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patil/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 3\n",
      "Accuracy score: 0.8090666666666667\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patil/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 4\n",
      "Accuracy score: 0.8075743432457662\n",
      "\n",
      "\n",
      "Average Accuracy score: 0.8075743432457662\n",
      "Classification report  = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      3252\n",
      "           1       0.84      0.82      0.83      4247\n",
      "\n",
      "    accuracy                           0.81      7499\n",
      "   macro avg       0.80      0.81      0.80      7499\n",
      "weighted avg       0.81      0.81      0.81      7499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df.toarray()\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gnb = RandomForestClassifier()\n",
    "#     print(type(X))\n",
    "#     print(np.any(np.isnan(X_train)))\n",
    "    gnb.fit(X_train, y_train)\n",
    "    deci_pred = gnb.predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print()\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))\n",
    "print (\"Classification report  = \\n\",classification_report(y_test, deci_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of both the classifiers is again around 0.81. This is less accurate than the one for sample data but it is still a good value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 40000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(max_features=40000,max_df = 10)\n",
    "transformed_df = vec.fit_transform(m_df2[\"text\"])\n",
    "transformed_df.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy score: 0.6843333333333333\n"
     ]
    }
   ],
   "source": [
    "X= transformed_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Using Random Forest Classifier\n",
    "\n",
    "rfc = MultinomialNB()\n",
    "\n",
    "#Fitting a Random Forest Classifier\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Average Accuracy score:\", rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a multinomial naïve Bayes classifier on Tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "Accuracy score: 0.6885748566857752\n",
      "\n",
      "\n",
      "For fold 2\n",
      "Accuracy score: 0.6866666666666666\n",
      "\n",
      "\n",
      "For fold 3\n",
      "Accuracy score: 0.6874666666666667\n",
      "\n",
      "\n",
      "For fold 4\n",
      "Accuracy score: 0.6803573809841312\n",
      "\n",
      "\n",
      "Average Accuracy score: 0.6803573809841312\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.40      0.52      3252\n",
      "           1       0.66      0.89      0.76      4247\n",
      "\n",
      "    accuracy                           0.68      7499\n",
      "   macro avg       0.70      0.65      0.64      7499\n",
      "weighted avg       0.70      0.68      0.66      7499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=4)\n",
    "i=0\n",
    "\n",
    "X = transformed_df.toarray()\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    i += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gnb = MultinomialNB()\n",
    "#     print(type(X))\n",
    "#     print(np.any(np.isnan(X_train)))\n",
    "    gnb.fit(X_train, y_train)\n",
    "    deci_pred = gnb.predict(X_test)\n",
    "    print(\"For fold {}\".format(i))\n",
    "    print(\"Accuracy score:\", gnb.score(X_test,y_test))\n",
    "    print()\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Average Accuracy score:\", gnb.score(X_test,y_test))\n",
    "print (\"Classification report \",classification_report(y_test, deci_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a Random Forest classifier on Tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436403241821431\n",
      "0.8526666666666667\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "rfc = RandomForestClassifier(n_estimators=10, verbose=True , n_jobs =3 )\n",
    "rfc.fit(transformed_df, y)\n",
    "vectors_test = vec.transform(m_df2[\"text\"])\n",
    "y_pred = gnb.predict(vectors_test)\n",
    "# y_pred = gnb.predict(m_df2[\"text\"])\n",
    "# print(\"Average Accuracy score:\", gnb.score(vectors_test,y))\n",
    "f1_score = metrics.f1_score(y, y_pred, average='macro')\n",
    "acc_score = metrics.accuracy_score(y, y_pred)\n",
    "print(f1_score)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy score: 0.6633333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "X= transformed_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Using Random Forest Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, verbose=True , n_jobs =3)\n",
    "\n",
    "#Fitting a Random Forest Classifier\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Average Accuracy score:\", rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train test split the accuracy score of Multinomial Gaussian Naive Bayes is much better than Random Forest Classifier. Using cross-validation as expected we get better values for the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference :\n",
    "\n",
    "https://www.ahmedbesbes.com/blog/sentiment-analysis-with-keras-and-word-2-vec\n",
    "\n",
    "https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
